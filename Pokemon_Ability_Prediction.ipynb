{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pokemon Ability Prediction Model\n",
    "\n",
    "This notebook analyzes Pokemon types and builds a machine learning model to predict Pokemon abilities based on their stats and characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original Pokemon types dataset\n",
    "df_types = pd.read_csv('data/pokemon.csv')\n",
    "print(\"Original dataset shape:\", df_types.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_types.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique Pokemon types\n",
    "all_types = []\n",
    "for types in df_types['Type']:\n",
    "    if pd.notna(types):\n",
    "        # Split by comma and strip whitespace\n",
    "        type_list = [t.strip() for t in types.split(',')]\n",
    "        all_types.extend(type_list)\n",
    "\n",
    "unique_types = sorted(set(all_types))\n",
    "print(f\"\\nTotal number of unique Pokemon types: {len(unique_types)}\")\n",
    "print(\"\\nUnique Pokemon types:\")\n",
    "for i, ptype in enumerate(unique_types, 1):\n",
    "    print(f\"{i:2d}. {ptype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the comprehensive dataset with abilities\n",
    "df_complete = pd.read_csv('data/pokemon_complete.csv', sep=';')\n",
    "print(\"\\nComplete dataset shape:\", df_complete.shape)\n",
    "print(\"\\nColumn names:\")\n",
    "print(df_complete.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the abilities column - it's stored as a string representation of a list\n",
    "import ast\n",
    "\n",
    "def parse_abilities(abilities_str):\n",
    "    try:\n",
    "        abilities = ast.literal_eval(abilities_str)\n",
    "        # Return the first ability as the primary one\n",
    "        return abilities[0] if abilities else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_complete['Primary_Ability'] = df_complete['Abilities'].apply(parse_abilities)\n",
    "\n",
    "# Parse types\n",
    "def parse_types(types_str):\n",
    "    try:\n",
    "        types = ast.literal_eval(types_str)\n",
    "        return types\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df_complete['Types_List'] = df_complete['Types'].apply(parse_types)\n",
    "df_complete['Type1'] = df_complete['Types_List'].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "df_complete['Type2'] = df_complete['Types_List'].apply(lambda x: x[1] if len(x) > 1 else None)\n",
    "\n",
    "print(\"Parsed abilities and types successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing abilities or stats\n",
    "df_clean = df_complete.dropna(subset=['Primary_Ability', 'HP', 'Attack', 'Defense', \n",
    "                                      'Special Attack', 'Special Defense', 'Speed', 'Type1'])\n",
    "\n",
    "print(f\"\\nDataset after cleaning: {df_clean.shape}\")\n",
    "print(f\"Number of unique abilities: {df_clean['Primary_Ability'].nunique()}\")\n",
    "\n",
    "# Show ability distribution\n",
    "ability_counts = df_clean['Primary_Ability'].value_counts()\n",
    "print(\"\\nTop 20 most common abilities:\")\n",
    "print(ability_counts.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to keep only abilities with at least 10 Pokemon\n",
    "ability_counts = df_clean['Primary_Ability'].value_counts()\n",
    "common_abilities = ability_counts[ability_counts >= 10].index.tolist()\n",
    "df_filtered = df_clean[df_clean['Primary_Ability'].isin(common_abilities)].copy()\n",
    "\n",
    "print(f\"\\nDataset after filtering rare abilities: {df_filtered.shape}\")\n",
    "print(f\"Number of abilities to predict: {len(common_abilities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stat distributions\n",
    "stat_columns = ['HP', 'Attack', 'Defense', 'Special Attack', 'Special Defense', 'Speed']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, stat in enumerate(stat_columns):\n",
    "    axes[idx].hist(df_filtered[stat], bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'Distribution of {stat}')\n",
    "    axes[idx].set_xlabel(stat)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap of stats\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df_filtered[stat_columns].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1)\n",
    "plt.title('Correlation Heatmap of Pokemon Stats')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average stats by type\n",
    "type_stats = df_filtered.groupby('Type1')[stat_columns].mean().round(1)\n",
    "type_stats['Total'] = type_stats.sum(axis=1)\n",
    "type_stats = type_stats.sort_values('Total', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "type_stats['Total'].plot(kind='bar')\n",
    "plt.title('Average Total Stats by Primary Type')\n",
    "plt.xlabel('Pokemon Type')\n",
    "plt.ylabel('Average Total Stats')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "df_filtered['Total_Stats'] = df_filtered[stat_columns].sum(axis=1)\n",
    "df_filtered['Physical_Ratio'] = df_filtered['Attack'] / (df_filtered['Attack'] + df_filtered['Special Attack'])\n",
    "df_filtered['Defense_Ratio'] = df_filtered['Defense'] / (df_filtered['Defense'] + df_filtered['Special Defense'])\n",
    "df_filtered['Speed_Percentile'] = pd.qcut(df_filtered['Speed'], q=4, labels=['Slow', 'Medium', 'Fast', 'Very Fast'])\n",
    "\n",
    "# Create binary features for type combinations\n",
    "for ptype in unique_types:\n",
    "    df_filtered[f'Has_{ptype}'] = df_filtered['Types_List'].apply(lambda x: 1 if ptype in x else 0)\n",
    "\n",
    "print(\"Created additional features successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "feature_columns = stat_columns + ['Total_Stats', 'Physical_Ratio', 'Defense_Ratio']\n",
    "feature_columns += [f'Has_{ptype}' for ptype in unique_types]\n",
    "\n",
    "X = df_filtered[feature_columns]\n",
    "y = df_filtered['Primary_Ability']\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Number of classes (abilities): {len(label_encoder.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(20)\n",
    "plt.barh(top_features['feature'], top_features['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Most Important Features - Random Forest')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, \n",
    "                              random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Neural Network\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation='relu', \n",
    "                         solver='adam', max_iter=500, random_state=42)\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nn_pred = nn_model.predict(X_test_scaled)\n",
    "nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "model_results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost', 'Neural Network'],\n",
    "    'Accuracy': [rf_accuracy, xgb_accuracy, nn_accuracy]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(model_results['Model'], model_results['Accuracy'])\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison - Ability Prediction Accuracy')\n",
    "for i, v in enumerate(model_results['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.3f}', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the best model\n",
    "best_model = rf_model  # Assuming Random Forest performs best\n",
    "best_pred = rf_pred\n",
    "\n",
    "# Classification report for top 10 abilities\n",
    "top_abilities = df_filtered['Primary_Ability'].value_counts().head(10).index\n",
    "top_ability_indices = [i for i, ability in enumerate(label_encoder.classes_) if ability in top_abilities]\n",
    "\n",
    "print(\"\\nClassification Report for Top 10 Most Common Abilities:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filter predictions and true labels for top abilities\n",
    "mask = np.isin(y_test, top_ability_indices)\n",
    "if mask.sum() > 0:\n",
    "    y_test_filtered = y_test[mask]\n",
    "    best_pred_filtered = best_pred[mask]\n",
    "    \n",
    "    report = classification_report(y_test_filtered, best_pred_filtered, \n",
    "                                 target_names=[label_encoder.classes_[i] for i in np.unique(y_test_filtered)],\n",
    "                                 zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pokemon_ability(name, hp, attack, defense, sp_attack, sp_defense, speed, types):\n",
    "    \"\"\"\n",
    "    Predict the ability of a Pokemon based on its stats and types.\n",
    "    \n",
    "    Parameters:\n",
    "    - name: Pokemon name (str)\n",
    "    - hp, attack, defense, sp_attack, sp_defense, speed: Base stats (int)\n",
    "    - types: List of Pokemon types (e.g., ['Fire', 'Flying'])\n",
    "    \"\"\"\n",
    "    # Create feature vector\n",
    "    features = {\n",
    "        'HP': hp,\n",
    "        'Attack': attack,\n",
    "        'Defense': defense,\n",
    "        'Special Attack': sp_attack,\n",
    "        'Special Defense': sp_defense,\n",
    "        'Speed': speed,\n",
    "        'Total_Stats': hp + attack + defense + sp_attack + sp_defense + speed,\n",
    "        'Physical_Ratio': attack / (attack + sp_attack),\n",
    "        'Defense_Ratio': defense / (defense + sp_defense)\n",
    "    }\n",
    "    \n",
    "    # Add type features\n",
    "    for ptype in unique_types:\n",
    "        features[f'Has_{ptype}'] = 1 if ptype in types else 0\n",
    "    \n",
    "    # Create dataframe with correct column order\n",
    "    feature_df = pd.DataFrame([features])[feature_columns]\n",
    "    \n",
    "    # Make prediction\n",
    "    ability_pred = best_model.predict(feature_df)[0]\n",
    "    ability_name = label_encoder.inverse_transform([ability_pred])[0]\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    probabilities = best_model.predict_proba(feature_df)[0]\n",
    "    top_3_indices = np.argsort(probabilities)[-3:][::-1]\n",
    "    top_3_abilities = [(label_encoder.inverse_transform([idx])[0], probabilities[idx]) \n",
    "                       for idx in top_3_indices]\n",
    "    \n",
    "    print(f\"\\nPrediction for {name}:\")\n",
    "    print(f\"Primary Type: {types[0] if types else 'Unknown'}\")\n",
    "    print(f\"Total Stats: {features['Total_Stats']}\")\n",
    "    print(\"\\nPredicted Ability: {}\\n\".format(ability_name))\n",
    "    print(\"Top 3 Most Likely Abilities:\")\n",
    "    for ability, prob in top_3_abilities:\n",
    "        print(f\"  - {ability}: {prob:.2%}\")\n",
    "    \n",
    "    return ability_name\n",
    "\n",
    "# Example predictions\n",
    "print(\"Example Predictions:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Predict for a Fire/Flying type with high attack\n",
    "predict_pokemon_ability(\"Charizard\", hp=78, attack=84, defense=78, \n",
    "                       sp_attack=109, sp_defense=85, speed=100, \n",
    "                       types=['Fire', 'Flying'])\n",
    "\n",
    "# Predict for a Water type with balanced stats\n",
    "predict_pokemon_ability(\"Blastoise\", hp=79, attack=83, defense=100, \n",
    "                       sp_attack=85, sp_defense=105, speed=78, \n",
    "                       types=['Water'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pokemon Ability Prediction Model Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"- Total Pokemon analyzed: {len(df_filtered)}\")\n",
    "print(f\"- Number of unique types: {len(unique_types)}\")\n",
    "print(f\"- Number of abilities predicted: {len(common_abilities)}\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"- Random Forest Accuracy: {rf_accuracy:.2%}\")\n",
    "print(f\"- XGBoost Accuracy: {xgb_accuracy:.2%}\")\n",
    "print(f\"- Neural Network Accuracy: {nn_accuracy:.2%}\")\n",
    "print(f\"\\nMost Important Features for Prediction:\")\n",
    "print(feature_importance.head(5).to_string(index=False))\n",
    "print(\"\\nThe model can predict Pokemon abilities based on their stats and types with reasonable accuracy.\")\n",
    "print(\"Stats like HP, Attack, and Speed are the most important predictors of abilities.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}